{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Goals data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.tabular import *\n",
    "import raw_data_utils\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Constants:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "INCLUDE_NEW_DF = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Get main df and format it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/ligamx/Goals-Match')\n",
    "raw_data_utils.format_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Get dataset of new games and concatenate it to df:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if INCLUDE_NEW_DF:\n",
    "    df_ns = pd.read_pickle('./data/ligamx/Goals-Match_new_season')\n",
    "    raw_data_utils.format_columns(df_ns)\n",
    "    df = pd.concat([df, df_ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Reset index and visualize current df:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>VIS</th>\n",
       "      <th>GL</th>\n",
       "      <th>GV</th>\n",
       "      <th>JRD</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>ANO</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>L_POS</th>\n",
       "      <th>L_JJ</th>\n",
       "      <th>L_JG</th>\n",
       "      <th>L_JE</th>\n",
       "      <th>L_JP</th>\n",
       "      <th>L_GF</th>\n",
       "      <th>L_GC</th>\n",
       "      <th>L_DIF</th>\n",
       "      <th>L_PTS</th>\n",
       "      <th>L_R_JG_JJ</th>\n",
       "      <th>L_R_JE_JJ</th>\n",
       "      <th>L_R_JP_JJ</th>\n",
       "      <th>L_R_GF_JJ</th>\n",
       "      <th>L_R_GC_JJ</th>\n",
       "      <th>L_R_DIF_JJ</th>\n",
       "      <th>L_R_PTS_JJ</th>\n",
       "      <th>V_POS</th>\n",
       "      <th>V_JJ</th>\n",
       "      <th>V_JG</th>\n",
       "      <th>V_JE</th>\n",
       "      <th>V_JP</th>\n",
       "      <th>V_GF</th>\n",
       "      <th>V_GC</th>\n",
       "      <th>V_DIF</th>\n",
       "      <th>V_PTS</th>\n",
       "      <th>V_R_JG_JJ</th>\n",
       "      <th>V_R_JE_JJ</th>\n",
       "      <th>V_R_JP_JJ</th>\n",
       "      <th>V_R_GF_JJ</th>\n",
       "      <th>V_R_GC_JJ</th>\n",
       "      <th>V_R_DIF_JJ</th>\n",
       "      <th>V_R_PTS_JJ</th>\n",
       "      <th>RES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>necaxa</td>\n",
       "      <td>atlas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15/5/2004</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>guadalajara</td>\n",
       "      <td>san luis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15/5/2004</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>irapuato</td>\n",
       "      <td>veracruz</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16/5/2004</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LOC       VIS   GL   GV   JRD      FECHA   HORA   ANO      TIPO  \\\n",
       "4921       necaxa     atlas  0.0  1.0  19.0  15/5/2004  17:00  2004  clausura   \n",
       "4922  guadalajara  san luis  4.0  1.0  19.0  15/5/2004  19:00  2004  clausura   \n",
       "4923     irapuato  veracruz  3.0  2.0  19.0  16/5/2004  17:00  2004  clausura   \n",
       "\n",
       "      L_POS  L_JJ  L_JG  L_JE  L_JP  L_GF  L_GC  L_DIF  L_PTS  L_R_JG_JJ  \\\n",
       "4921   14.0  19.0   5.0   6.0   8.0  22.0  26.0   -4.0   21.0        0.0   \n",
       "4922    4.0  19.0   9.0   5.0   5.0  29.0  23.0    6.0   32.0        0.0   \n",
       "4923   11.0  19.0   6.0   8.0   5.0  23.0  30.0   -7.0   26.0        0.0   \n",
       "\n",
       "      L_R_JE_JJ  L_R_JP_JJ  L_R_GF_JJ  L_R_GC_JJ  L_R_DIF_JJ  L_R_PTS_JJ  \\\n",
       "4921        0.0        1.0        2.0        3.0        -1.0         0.0   \n",
       "4922        1.0        0.0        1.0        1.0         0.0         1.0   \n",
       "4923        1.0        0.0        1.0        1.0         0.0         1.0   \n",
       "\n",
       "      V_POS  V_JJ  V_JG  V_JE  V_JP  V_GF  V_GC  V_DIF  V_PTS  V_R_JG_JJ  \\\n",
       "4921    7.0  19.0   6.0   9.0   4.0  28.0  25.0    3.0   27.0        0.0   \n",
       "4922   18.0  19.0   4.0   6.0   9.0  23.0  34.0  -11.0   18.0        0.0   \n",
       "4923   20.0  19.0   4.0   5.0  10.0  25.0  41.0  -16.0   17.0        0.0   \n",
       "\n",
       "      V_R_JE_JJ  V_R_JP_JJ  V_R_GF_JJ  V_R_GC_JJ  V_R_DIF_JJ  V_R_PTS_JJ  RES  \n",
       "4921        1.0        0.0        1.0        1.0         0.0         1.0    0  \n",
       "4922        1.0        0.0        1.0        1.0         0.0         1.0    2  \n",
       "4923        0.0        1.0        2.0        6.0        -4.0         0.0    2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop = True, inplace = True)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sorting df ascendingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = raw_data_utils.sort_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Getting individual teams in 'Team, ContraryTeam' format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JRD</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>ANO</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>EQ_POS</th>\n",
       "      <th>EQ_JJ</th>\n",
       "      <th>EQ_JG</th>\n",
       "      <th>EQ_JE</th>\n",
       "      <th>EQ_JP</th>\n",
       "      <th>EQ_GF</th>\n",
       "      <th>EQ_GC</th>\n",
       "      <th>EQ_DIF</th>\n",
       "      <th>EQ_PTS</th>\n",
       "      <th>EQ_R_JG_JJ</th>\n",
       "      <th>EQ_R_JE_JJ</th>\n",
       "      <th>EQ_R_JP_JJ</th>\n",
       "      <th>EQ_R_GF_JJ</th>\n",
       "      <th>EQ_R_GC_JJ</th>\n",
       "      <th>EQ_R_DIF_JJ</th>\n",
       "      <th>EQ_R_PTS_JJ</th>\n",
       "      <th>EQC_POS</th>\n",
       "      <th>EQC_JJ</th>\n",
       "      <th>EQC_JG</th>\n",
       "      <th>EQC_JE</th>\n",
       "      <th>EQC_JP</th>\n",
       "      <th>EQC_GF</th>\n",
       "      <th>EQC_GC</th>\n",
       "      <th>EQC_DIF</th>\n",
       "      <th>EQC_PTS</th>\n",
       "      <th>EQC_R_JG_JJ</th>\n",
       "      <th>EQC_R_JE_JJ</th>\n",
       "      <th>EQC_R_JP_JJ</th>\n",
       "      <th>EQC_R_GF_JJ</th>\n",
       "      <th>EQC_R_GC_JJ</th>\n",
       "      <th>EQC_R_DIF_JJ</th>\n",
       "      <th>EQC_R_PTS_JJ</th>\n",
       "      <th>RES</th>\n",
       "      <th>ES_LOC</th>\n",
       "      <th>EQ</th>\n",
       "      <th>EQC</th>\n",
       "      <th>G_EQ</th>\n",
       "      <th>G_EQC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20/4/2013</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>san luis</td>\n",
       "      <td>queretaro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>16.0</td>\n",
       "      <td>27/4/2013</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>san luis</td>\n",
       "      <td>tijuana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5/5/2013</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>san luis</td>\n",
       "      <td>toluca</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      JRD      FECHA   HORA   ANO      TIPO  EQ_POS  EQ_JJ  EQ_JG  EQ_JE  \\\n",
       "286  15.0  20/4/2013  17:00  2013  clausura    16.0   15.0    2.0    4.0   \n",
       "287  16.0  27/4/2013  21:00  2013  clausura    18.0   16.0    3.0    4.0   \n",
       "288  17.0   5/5/2013  12:00  2013  clausura    17.0   17.0    4.0    4.0   \n",
       "\n",
       "     EQ_JP  EQ_GF  EQ_GC  EQ_DIF  EQ_PTS  EQ_R_JG_JJ  EQ_R_JE_JJ  EQ_R_JP_JJ  \\\n",
       "286    9.0   17.0   25.0    -8.0    10.0         0.0         1.0         0.0   \n",
       "287    9.0   18.0   25.0    -7.0    13.0         0.0         0.0         1.0   \n",
       "288    9.0   19.0   25.0    -6.0    16.0         1.0         0.0         0.0   \n",
       "\n",
       "     EQ_R_GF_JJ  EQ_R_GC_JJ  EQ_R_DIF_JJ  EQ_R_PTS_JJ  EQC_POS  EQC_JJ  \\\n",
       "286         2.0         2.0          0.0          1.0     11.0    15.0   \n",
       "287         1.0         2.0         -1.0          0.0     11.0    16.0   \n",
       "288         1.0         0.0          1.0          3.0     12.0    17.0   \n",
       "\n",
       "     EQC_JG  EQC_JE  EQC_JP  EQC_GF  EQC_GC  EQC_DIF  EQC_PTS  EQC_R_JG_JJ  \\\n",
       "286     5.0     6.0     4.0    14.0    16.0     -2.0     21.0          0.0   \n",
       "287     5.0     3.0     8.0    15.0    21.0     -6.0     18.0          0.0   \n",
       "288     5.0     3.0     9.0    14.0    21.0     -7.0     18.0          0.0   \n",
       "\n",
       "     EQC_R_JE_JJ  EQC_R_JP_JJ  EQC_R_GF_JJ  EQC_R_GC_JJ  EQC_R_DIF_JJ  \\\n",
       "286          0.0          1.0          0.0          1.0          -1.0   \n",
       "287          0.0          1.0          1.0          2.0          -1.0   \n",
       "288          0.0          1.0          1.0          2.0          -1.0   \n",
       "\n",
       "     EQC_R_PTS_JJ  RES  ES_LOC        EQ        EQC  G_EQ  G_EQC  \n",
       "286           0.0    0   False  san luis  queretaro   1.0    2.0  \n",
       "287           0.0    2    True  san luis    tijuana   1.0    0.0  \n",
       "288           0.0    2   False  san luis     toluca   1.0    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = raw_data_utils.get_ind_teams(df)\n",
    "teams[4].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clean teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Remove all duplicated jrds from all teams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morelia has duplicate jrds -> will remove them\n",
      "necaxa has duplicate jrds -> will remove them\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_utils.remove_duplicate_jrds(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Assert that all duplicated jrds were removed succesfully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert (raw_data_utils.remove_duplicate_jrds(teams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data analyzis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Check games above and below a certain bound, only for analysis sake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "above_bound, below_bound = raw_data_utils.get_teams_split_games(teams, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'santos': 545,\n",
       " 'atlante': 357,\n",
       " 'america': 545,\n",
       " 'atlas': 545,\n",
       " 'morelia': 545,\n",
       " 'chiapas': 459,\n",
       " 'monterrey': 545,\n",
       " 'toluca': 545,\n",
       " 'cruz azul': 545,\n",
       " 'guadalajara': 545,\n",
       " 'tigres': 545,\n",
       " 'necaxa': 341,\n",
       " 'unam': 545,\n",
       " 'puebla': 477,\n",
       " 'veracruz': 376,\n",
       " 'pachuca': 545,\n",
       " 'queretaro': 392}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'san luis': 289,\n",
       " 'uag': 289,\n",
       " 'irapuato': 18,\n",
       " 'sinaloa': 102,\n",
       " 'indios': 67,\n",
       " 'tijuana': 290,\n",
       " 'leon': 256,\n",
       " 'u de g': 34,\n",
       " 'lobos buap': 68,\n",
       " 'atletico de san luis': 18,\n",
       " 'fc juarez': 18}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.tabular import *\n",
    "from fastai import *\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define dependent, cat and cont variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = ['RES']\n",
    "#categorical values\n",
    "cat_vars = ['EQ', 'EQC', 'ES_LOC', 'EQ_POS', 'EQC_POS', 'JRD', 'ANO', 'TIPO']\n",
    "#continious variables\n",
    "cont_vars = ['EQ_R_JG_JJ', 'EQ_R_JE_JJ', 'EQ_R_JP_JJ', 'EQ_R_GF_JJ', 'EQ_R_GC_JJ', 'EQ_R_DIF_JJ', 'EQ_R_PTS_JJ',\n",
    "             'EQC_R_JG_JJ', 'EQC_R_JE_JJ', 'EQC_R_JP_JJ', 'EQC_R_GF_JJ', 'EQC_R_GC_JJ', 'EQC_R_DIF_JJ', 'EQC_R_PTS_JJ']\n",
    "procs = [Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the universe of the given columns across all teams**\n",
    "\n",
    "This is done so that when we map categories to numbers to each categorical variable we end up with the exact same mapping.\n",
    "\n",
    "**NOTE: this muyst be done for EVERY element in cat_vars!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_equipos = list(data_utils.get_col_universe_across_teams(teams, ['EQ', 'EQC'])); all_equipos.sort()\n",
    "all_pos = list(data_utils.get_col_universe_across_teams(teams, ['EQ_POS', 'EQC_POS'])); all_pos.sort()\n",
    "all_jrd = list(data_utils.get_col_universe_across_teams(teams, ['JRD'])); all_jrd.sort()\n",
    "all_ano = list(data_utils.get_col_universe_across_teams(teams, ['ANO'])); all_ano.sort()\n",
    "all_tipo = list(data_utils.get_col_universe_across_teams(teams, ['TIPO'])); all_tipo.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add missing categories to the categorical variables givn in cat_mapping in the form of (cat_var, universe)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapping = {\n",
    "    'EQ' : all_equipos,\n",
    "    'EQC' : all_equipos,\n",
    "#     'ES_LOC', currently not using this one since all teams have the universe already\n",
    "    'EQ_POS' : all_pos,\n",
    "    'EQC_POS': all_pos,\n",
    "    'JRD' : all_jrd,\n",
    "    'ANO' : all_ano, \n",
    "    'TIPO' : all_tipo,\n",
    "}\n",
    "data_utils.add_missing_categories_all_teams(teams, cat_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert teams to datasets by using fastai TabularList and then extracting the datasets from it**\n",
    "\n",
    "We do this since the team_ds's will get converted to tensor lists which we will use to build our dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ds = data_utils.get_datasets_from_teams(teams, dep_vars, cat_vars, cont_vars, procs, './data/ligamx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teams_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the maximum (latest) jrd, ano, tipo across all teams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "JRD_POS = cat_vars.index('JRD')\n",
    "ANO_POS = cat_vars.index('ANO')\n",
    "TIPO_POS = cat_vars.index('TIPO')\n",
    "\n",
    "mx_jrd, mx_ano, mx_tipo = data_utils.get_max_jrd(teams_ds, JRD_POS, ANO_POS, TIPO_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the jrds that must be included in the validation dataset and removed from the current training set for all teams(if present)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid_bptt = 5\n",
    "valid_jrds = data_utils.get_valid_jrds(n_valid_bptt, mx_jrd, mx_ano, mx_tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating validation dataset for all teams and removing validation jrds from training dataset if present()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_valid_ds = data_utils.split_valid_jrds(teams_ds, valid_jrds, n_valid_bptt, JRD_POS, ANO_POS, TIPO_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(teams_valid_ds[0][1]) == n_valid_bptt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating correctness of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the last jrd, ano, tipo from the team at the 0th position in our teams_ds list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16, 1, 540)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = 0\n",
    "ps = len(teams_ds[tm][1])\n",
    "teams_ds[tm][0][0][ps-1][JRD_POS].item(), teams_ds[tm][0][0][ps-1][ANO_POS].item(), teams_ds[tm][0][0][ps-1][TIPO_POS].item(), ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking that all teams have a different categorical numbers**\n",
    "Note that this was fixed above by setting the universe of each categorical value across all teams to each individual team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_set = set()\n",
    "for i in range(len(teams_ds)):\n",
    "    assert(teams_ds[i][0][0][0][0].item() not in teams_set)\n",
    "    teams_set.add(teams_ds[i][0][0][0][0].item())\n",
    "teams_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4480097481722177 0.2806661251015435 0.27132412672623885\n"
     ]
    }
   ],
   "source": [
    "loc_wins, tie, vis_wins = len(df[df.RES == 2]), len(df[df.RES == 1]), len(df[df.RES==0])\n",
    "\n",
    "assert(loc_wins + tie + vis_wins == len(df))\n",
    "\n",
    "print(loc_wins/len(df), tie/len(df), vis_wins/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_tab_ds import RNNTabDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training_bptt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "rnn_tab_ds = RNNTabDataset(teams_ds, n_training_bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "rnn_tab_ds_valid = RNNTabDataset(teams_valid_ds, n_valid_bptt, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dl = DataLoader(rnn_tab_ds, batches, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dl_valid = DataLoader(rnn_tab_ds_valid, batches, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal Learning Rate CLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class and function that help us a good learning rate for our model\n",
    "from opt_lr import CLR, find_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once Cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that helps us implement one cylce in our model\n",
    "from one_cycle import OneCycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up cuda if possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# Class that contains the model to predict game results along a function that helps us identify matches in the games from a jornada\n",
    "from rnn_tabular_model import RnnTabularModel\n",
    "\n",
    "# Model utils\n",
    "from model_utils import get_matching_idxs, get_loss, pred, accuracy, get_res, view_predictions_and_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 5, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_it = iter(curr_dl_valid)\n",
    "tst = next(curr_it)\n",
    "\n",
    "sample_cat = tst[0][0][0].type(torch.LongTensor).to(device)\n",
    "sample_cont = tst[0][1][0].to(device)\n",
    "sample_res_not_proc = tst[1][0].type(torch.LongTensor).to(device)\n",
    "sample_res = get_res(sample_cat, sample_res_not_proc)\n",
    "\n",
    "sample_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EQ', 'EQC', 'ES_LOC', 'EQ_POS', 'EQC_POS', 'JRD', 'ANO', 'TIPO']\n"
     ]
    }
   ],
   "source": [
    "print(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(29, 30), (29, 30), (3, 10), (21, 30), (21, 30), (20, 1), (17, 1), (3, 1)]\n",
    "n_cont = len(cont_vars)\n",
    "out_sz = 3\n",
    "out_sz_rnn = 20\n",
    "lyrs = 2\n",
    "bs = 28\n",
    "dropout_embeds = 0.3\n",
    "dropout_reg = 0.3\n",
    "\n",
    "wd = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating model instance, loss criterion and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with hyperparameters\n",
    "model = RnnTabularModel(emb_szs, n_cont, out_sz, out_sz_rnn, lyrs, bs, dropout_reg, dropout_embeds)\n",
    "\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 40\n",
    "lr = 1e-3\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def find_lr(loss_func, opt, clr, model):\n",
    "# clr = CLR(curr_dl)\n",
    "# find_lr(criterion, optimizer, clr, model, curr_dl)\n",
    "# clr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_utils import changeLr, changeLrAndMomentums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40....... Train Loss: 1.1098...... Last batch train Loss: 1.1021...... Valid Loss: 1.1061...... Valid acc: 0.3778 LR: 0.0010\n",
      "Epoch: 2/40....... Train Loss: 1.0966...... Last batch train Loss: 1.0880...... Valid Loss: 1.0858...... Valid acc: 0.4667 LR: 0.0010\n",
      "Epoch: 3/40....... Train Loss: 1.0907...... Last batch train Loss: 1.0848...... Valid Loss: 1.0665...... Valid acc: 0.5778 LR: 0.0010\n",
      "Epoch: 4/40....... Train Loss: 1.0857...... Last batch train Loss: 1.0696...... Valid Loss: 1.0349...... Valid acc: 0.6000 LR: 0.0010\n",
      "Epoch: 5/40....... Train Loss: 1.0807...... Last batch train Loss: 1.0846...... Valid Loss: 1.0102...... Valid acc: 0.5556 LR: 0.0010\n",
      "Epoch: 6/40....... Train Loss: 1.0756...... Last batch train Loss: 1.0582...... Valid Loss: 0.9914...... Valid acc: 0.5556 LR: 0.0010\n",
      "Epoch: 7/40....... Train Loss: 1.0731...... Last batch train Loss: 1.0654...... Valid Loss: 1.0023...... Valid acc: 0.5778 LR: 0.0010\n",
      "Epoch: 8/40....... Train Loss: 1.0668...... Last batch train Loss: 1.0385...... Valid Loss: 0.9773...... Valid acc: 0.6222 LR: 0.0010\n",
      "Epoch: 9/40....... Train Loss: 1.0560...... Last batch train Loss: 1.0393...... Valid Loss: 0.9704...... Valid acc: 0.5556 LR: 0.0010\n",
      "Epoch: 10/40....... Train Loss: 1.0514...... Last batch train Loss: 1.0238...... Valid Loss: 0.9630...... Valid acc: 0.6000 LR: 0.0010\n",
      "Epoch: 11/40....... Train Loss: 1.0475...... Last batch train Loss: 1.0028...... Valid Loss: 0.9735...... Valid acc: 0.6000 LR: 0.0010\n",
      "Epoch: 12/40....... Train Loss: 1.0456...... Last batch train Loss: 1.0210...... Valid Loss: 0.9719...... Valid acc: 0.5333 LR: 0.0010\n",
      "Epoch: 13/40....... Train Loss: 1.0318...... Last batch train Loss: 1.0125...... Valid Loss: 0.9681...... Valid acc: 0.5556 LR: 0.0010\n",
      "Epoch: 14/40....... Train Loss: 1.0369...... Last batch train Loss: 1.0443...... Valid Loss: 0.9827...... Valid acc: 0.5778 LR: 0.0010\n",
      "Epoch: 15/40....... Train Loss: 1.0301...... Last batch train Loss: 1.0350...... Valid Loss: 0.9784...... Valid acc: 0.5111 LR: 0.0010\n",
      "Epoch: 16/40....... Train Loss: 1.0187...... Last batch train Loss: 1.0005...... Valid Loss: 0.9842...... Valid acc: 0.5556 LR: 0.0010\n",
      "Epoch: 17/40....... Train Loss: 1.0107...... Last batch train Loss: 1.0058...... Valid Loss: 0.9986...... Valid acc: 0.5333 LR: 0.0010\n",
      "Epoch: 18/40....... Train Loss: 0.9985...... Last batch train Loss: 1.0040...... Valid Loss: 1.0115...... Valid acc: 0.4889 LR: 0.0010\n",
      "Epoch: 19/40....... Train Loss: 0.9928...... Last batch train Loss: 0.9886...... Valid Loss: 1.0107...... Valid acc: 0.4889 LR: 0.0010\n",
      "Epoch: 20/40....... Train Loss: 0.9770...... Last batch train Loss: 0.9468...... Valid Loss: 1.0295...... Valid acc: 0.5333 LR: 0.0010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-841ff4c18b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does backpropagation and calculates gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Updates the weights accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl_mp/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl_mp/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "# Average loss in all batches\n",
    "train_loss_avgs = [0 for i in range(len(iter(curr_dl)))]\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    dl_it = iter(curr_dl)\n",
    "    \n",
    "    # resetting our h mtrx and setting model to train mode\n",
    "    model.reset_h()\n",
    "    model.train()\n",
    "    \n",
    "    # loss accumulative across batches\n",
    "    ttl_train_loss = 0;\n",
    "    for i_batch, curr_batch in enumerate(dl_it):\n",
    "\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        x_cat, x_cont = curr_batch[0][0][0].type(torch.LongTensor).to(device), curr_batch[0][1][0].to(device)\n",
    "        \n",
    "        # getting cat'ed res from current batch \n",
    "        res = get_res(x_cat, curr_batch[1][0].type(torch.LongTensor).to(device))\n",
    "\n",
    "        # calculating model output\n",
    "        output = model(x_cat, x_cont)\n",
    "        loss = criterion(output, res)\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordingly\n",
    "        \n",
    "        # updating ttl train loss\n",
    "        ttl_train_loss += loss.item()\n",
    "        \n",
    "        # updating loss averages\n",
    "        train_loss_avgs[i_batch] += loss.item()/(n_epochs)\n",
    "        \n",
    "        if i_batch == len(dl_it)-1:\n",
    "            model.eval()\n",
    "            loss_valid = get_loss(model, sample_cat, sample_cont, sample_res)\n",
    "            accuracy_valid = accuracy(model, sample_cat, sample_cont, sample_res)\n",
    "    \n",
    "    if epoch%1 == 0:\n",
    "        print(\"Epoch: {}/{}.......\".format(epoch, n_epochs), end=' ')\n",
    "        print(\"Train Loss: {:.4f}......\".format(ttl_train_loss/(len(dl_it))), end = ' ')\n",
    "        print(\"Last batch train Loss: {:.4f}......\".format(loss.item()), end = ' ')\n",
    "        print(\"Valid Loss: {:.4f}......\".format(loss_valid.item()), end = ' ')\n",
    "        print(\"Valid acc: {:.4f}\".format(accuracy_valid), end=' ')\n",
    "        print(\"LR: {:.4f}\".format(optimizer.param_groups[0]['lr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./models/1/1\"\n",
    "# torch.save(model.state_dict(), save_path)\n",
    "# model = RnnTabularModel(emb_szs, n_cont, out_sz, lyrs, bs, dropout_reg, dropout_embeds)\n",
    "# model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    plt.xlabel(\"batch\")\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.plot([i+1 for i in range(len(losses))], losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(loss_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_pred, sample_prob, m_out= pred(model, sample_cat, sample_cont, sample_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy(model, sample_cat, sample_cont, sample_res)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
