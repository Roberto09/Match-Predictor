{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.tabular import *\n",
    "import raw_data_utils\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Constants:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "INCLUDE_NEW_DF = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Get main df and format it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/ligamx/Goals-Match')\n",
    "raw_data_utils.format_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Get dataset of new games and concatenate it to df:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if INCLUDE_NEW_DF:\n",
    "    df_ns = pd.read_pickle('./data/ligamx/Goals-Match_new_season')\n",
    "    raw_data_utils.format_columns(df_ns)\n",
    "    df = pd.concat([df, df_ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Reset index and visualize current df:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>VIS</th>\n",
       "      <th>GL</th>\n",
       "      <th>GV</th>\n",
       "      <th>JRD</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>ANO</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>L_POS</th>\n",
       "      <th>L_JJ</th>\n",
       "      <th>L_JG</th>\n",
       "      <th>L_JE</th>\n",
       "      <th>L_JP</th>\n",
       "      <th>L_GF</th>\n",
       "      <th>L_GC</th>\n",
       "      <th>L_DIF</th>\n",
       "      <th>L_PTS</th>\n",
       "      <th>L_R_JG_JJ</th>\n",
       "      <th>L_R_JE_JJ</th>\n",
       "      <th>L_R_JP_JJ</th>\n",
       "      <th>L_R_GF_JJ</th>\n",
       "      <th>L_R_GC_JJ</th>\n",
       "      <th>L_R_DIF_JJ</th>\n",
       "      <th>L_R_PTS_JJ</th>\n",
       "      <th>V_POS</th>\n",
       "      <th>V_JJ</th>\n",
       "      <th>V_JG</th>\n",
       "      <th>V_JE</th>\n",
       "      <th>V_JP</th>\n",
       "      <th>V_GF</th>\n",
       "      <th>V_GC</th>\n",
       "      <th>V_DIF</th>\n",
       "      <th>V_PTS</th>\n",
       "      <th>V_R_JG_JJ</th>\n",
       "      <th>V_R_JE_JJ</th>\n",
       "      <th>V_R_JP_JJ</th>\n",
       "      <th>V_R_GF_JJ</th>\n",
       "      <th>V_R_GC_JJ</th>\n",
       "      <th>V_R_DIF_JJ</th>\n",
       "      <th>V_R_PTS_JJ</th>\n",
       "      <th>RES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>necaxa</td>\n",
       "      <td>atlas</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15/5/2004</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>guadalajara</td>\n",
       "      <td>san luis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15/5/2004</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>irapuato</td>\n",
       "      <td>veracruz</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>16/5/2004</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>clausura</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LOC       VIS   GL   GV   JRD      FECHA   HORA   ANO      TIPO  \\\n",
       "4921       necaxa     atlas  0.0  1.0  19.0  15/5/2004  17:00  2004  clausura   \n",
       "4922  guadalajara  san luis  4.0  1.0  19.0  15/5/2004  19:00  2004  clausura   \n",
       "4923     irapuato  veracruz  3.0  2.0  19.0  16/5/2004  17:00  2004  clausura   \n",
       "\n",
       "      L_POS  L_JJ  L_JG  L_JE  L_JP  L_GF  L_GC  L_DIF  L_PTS  L_R_JG_JJ  \\\n",
       "4921   14.0  19.0   5.0   6.0   8.0  22.0  26.0   -4.0   21.0        0.0   \n",
       "4922    4.0  19.0   9.0   5.0   5.0  29.0  23.0    6.0   32.0        0.0   \n",
       "4923   11.0  19.0   6.0   8.0   5.0  23.0  30.0   -7.0   26.0        0.0   \n",
       "\n",
       "      L_R_JE_JJ  L_R_JP_JJ  L_R_GF_JJ  L_R_GC_JJ  L_R_DIF_JJ  L_R_PTS_JJ  \\\n",
       "4921        0.0        1.0        2.0        3.0        -1.0         0.0   \n",
       "4922        1.0        0.0        1.0        1.0         0.0         1.0   \n",
       "4923        1.0        0.0        1.0        1.0         0.0         1.0   \n",
       "\n",
       "      V_POS  V_JJ  V_JG  V_JE  V_JP  V_GF  V_GC  V_DIF  V_PTS  V_R_JG_JJ  \\\n",
       "4921    7.0  19.0   6.0   9.0   4.0  28.0  25.0    3.0   27.0        0.0   \n",
       "4922   18.0  19.0   4.0   6.0   9.0  23.0  34.0  -11.0   18.0        0.0   \n",
       "4923   20.0  19.0   4.0   5.0  10.0  25.0  41.0  -16.0   17.0        0.0   \n",
       "\n",
       "      V_R_JE_JJ  V_R_JP_JJ  V_R_GF_JJ  V_R_GC_JJ  V_R_DIF_JJ  V_R_PTS_JJ  RES  \n",
       "4921        1.0        0.0        1.0        1.0         0.0         1.0    0  \n",
       "4922        1.0        0.0        1.0        1.0         0.0         1.0    2  \n",
       "4923        0.0        1.0        2.0        6.0        -4.0         0.0    2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop = True, inplace = True)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sorting df ascendingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = raw_data_utils.sort_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Getting individual teams in 'Team, ContraryTeam' format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JRD</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HORA</th>\n",
       "      <th>ANO</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>EQ_POS</th>\n",
       "      <th>EQ_JJ</th>\n",
       "      <th>EQ_JG</th>\n",
       "      <th>EQ_JE</th>\n",
       "      <th>EQ_JP</th>\n",
       "      <th>EQ_GF</th>\n",
       "      <th>EQ_GC</th>\n",
       "      <th>EQ_DIF</th>\n",
       "      <th>EQ_PTS</th>\n",
       "      <th>EQ_R_JG_JJ</th>\n",
       "      <th>EQ_R_JE_JJ</th>\n",
       "      <th>EQ_R_JP_JJ</th>\n",
       "      <th>EQ_R_GF_JJ</th>\n",
       "      <th>EQ_R_GC_JJ</th>\n",
       "      <th>EQ_R_DIF_JJ</th>\n",
       "      <th>EQ_R_PTS_JJ</th>\n",
       "      <th>EQC_POS</th>\n",
       "      <th>EQC_JJ</th>\n",
       "      <th>EQC_JG</th>\n",
       "      <th>EQC_JE</th>\n",
       "      <th>EQC_JP</th>\n",
       "      <th>EQC_GF</th>\n",
       "      <th>EQC_GC</th>\n",
       "      <th>EQC_DIF</th>\n",
       "      <th>EQC_PTS</th>\n",
       "      <th>EQC_R_JG_JJ</th>\n",
       "      <th>EQC_R_JE_JJ</th>\n",
       "      <th>EQC_R_JP_JJ</th>\n",
       "      <th>EQC_R_GF_JJ</th>\n",
       "      <th>EQC_R_GC_JJ</th>\n",
       "      <th>EQC_R_DIF_JJ</th>\n",
       "      <th>EQC_R_PTS_JJ</th>\n",
       "      <th>RES</th>\n",
       "      <th>ES_LOC</th>\n",
       "      <th>EQ</th>\n",
       "      <th>EQC</th>\n",
       "      <th>G_EQ</th>\n",
       "      <th>G_EQC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20/4/2013</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>san luis</td>\n",
       "      <td>queretaro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>16.0</td>\n",
       "      <td>27/4/2013</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>san luis</td>\n",
       "      <td>tijuana</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>17.0</td>\n",
       "      <td>5/5/2013</td>\n",
       "      <td>12:00</td>\n",
       "      <td>2013</td>\n",
       "      <td>clausura</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>san luis</td>\n",
       "      <td>toluca</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      JRD      FECHA   HORA   ANO      TIPO  EQ_POS  EQ_JJ  EQ_JG  EQ_JE  \\\n",
       "286  15.0  20/4/2013  17:00  2013  clausura    16.0   15.0    2.0    4.0   \n",
       "287  16.0  27/4/2013  21:00  2013  clausura    18.0   16.0    3.0    4.0   \n",
       "288  17.0   5/5/2013  12:00  2013  clausura    17.0   17.0    4.0    4.0   \n",
       "\n",
       "     EQ_JP  EQ_GF  EQ_GC  EQ_DIF  EQ_PTS  EQ_R_JG_JJ  EQ_R_JE_JJ  EQ_R_JP_JJ  \\\n",
       "286    9.0   17.0   25.0    -8.0    10.0         0.0         1.0         0.0   \n",
       "287    9.0   18.0   25.0    -7.0    13.0         0.0         0.0         1.0   \n",
       "288    9.0   19.0   25.0    -6.0    16.0         1.0         0.0         0.0   \n",
       "\n",
       "     EQ_R_GF_JJ  EQ_R_GC_JJ  EQ_R_DIF_JJ  EQ_R_PTS_JJ  EQC_POS  EQC_JJ  \\\n",
       "286         2.0         2.0          0.0          1.0     11.0    15.0   \n",
       "287         1.0         2.0         -1.0          0.0     11.0    16.0   \n",
       "288         1.0         0.0          1.0          3.0     12.0    17.0   \n",
       "\n",
       "     EQC_JG  EQC_JE  EQC_JP  EQC_GF  EQC_GC  EQC_DIF  EQC_PTS  EQC_R_JG_JJ  \\\n",
       "286     5.0     6.0     4.0    14.0    16.0     -2.0     21.0          0.0   \n",
       "287     5.0     3.0     8.0    15.0    21.0     -6.0     18.0          0.0   \n",
       "288     5.0     3.0     9.0    14.0    21.0     -7.0     18.0          0.0   \n",
       "\n",
       "     EQC_R_JE_JJ  EQC_R_JP_JJ  EQC_R_GF_JJ  EQC_R_GC_JJ  EQC_R_DIF_JJ  \\\n",
       "286          0.0          1.0          0.0          1.0          -1.0   \n",
       "287          0.0          1.0          1.0          2.0          -1.0   \n",
       "288          0.0          1.0          1.0          2.0          -1.0   \n",
       "\n",
       "     EQC_R_PTS_JJ  RES  ES_LOC        EQ        EQC  G_EQ  G_EQC  \n",
       "286           0.0    0   False  san luis  queretaro   1.0    2.0  \n",
       "287           0.0    2    True  san luis    tijuana   1.0    0.0  \n",
       "288           0.0    2   False  san luis     toluca   1.0    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = raw_data_utils.get_ind_teams(df)\n",
    "teams[4].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove all duplicated jrds from all teams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morelia has duplicate jrds -> will remove them\n",
      "necaxa has duplicate jrds -> will remove them\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_utils.remove_duplicate_jrds(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the PREV_RES column with the result from the previous game**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_utils.aggregate_prev_results(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assert that all duplicated jrds were removed succesfully**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (raw_data_utils.remove_duplicate_jrds(teams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analyzis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check games above and below a certain bound, only for analysis sake**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "above_bound, below_bound = raw_data_utils.get_teams_split_games(teams, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'santos': 545,\n",
       " 'atlante': 357,\n",
       " 'america': 545,\n",
       " 'atlas': 545,\n",
       " 'morelia': 545,\n",
       " 'chiapas': 459,\n",
       " 'monterrey': 545,\n",
       " 'toluca': 545,\n",
       " 'cruz azul': 545,\n",
       " 'guadalajara': 545,\n",
       " 'tigres': 545,\n",
       " 'necaxa': 341,\n",
       " 'unam': 545,\n",
       " 'puebla': 477,\n",
       " 'veracruz': 376,\n",
       " 'pachuca': 545,\n",
       " 'queretaro': 392}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'san luis': 289,\n",
       " 'uag': 289,\n",
       " 'irapuato': 18,\n",
       " 'sinaloa': 102,\n",
       " 'indios': 67,\n",
       " 'tijuana': 290,\n",
       " 'leon': 256,\n",
       " 'u de g': 34,\n",
       " 'lobos buap': 68,\n",
       " 'atletico de san luis': 18,\n",
       " 'fc juarez': 18}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.tabular import *\n",
    "from fastai import *\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define dependent, cat and cont variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = ['RES']\n",
    "#categorical values\n",
    "cat_vars = ['EQ', 'EQC', 'ES_LOC', 'EQ_POS', 'EQC_POS', 'JRD', 'ANO', 'TIPO', 'PREV_RES', 'PREV_G_EQ', 'PREV_G_EQC']\n",
    "#continious variables\n",
    "cont_vars = ['EQ_R_JG_JJ', 'EQ_R_JE_JJ', 'EQ_R_JP_JJ', 'EQ_R_GF_JJ', 'EQ_R_GC_JJ', 'EQ_R_DIF_JJ', 'EQ_R_PTS_JJ',\n",
    "             'EQC_R_JG_JJ', 'EQC_R_JE_JJ', 'EQC_R_JP_JJ', 'EQC_R_GF_JJ', 'EQC_R_GC_JJ', 'EQC_R_DIF_JJ', 'EQC_R_PTS_JJ']\n",
    "procs = [Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the universe of the given columns across all teams**\n",
    "\n",
    "This is done so that when we map categories to numbers to each categorical variable we end up with the exact same mapping.\n",
    "\n",
    "**NOTE: this muyst be done for EVERY element in cat_vars!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_equipos = list(data_utils.get_col_universe_across_teams(teams, ['EQ', 'EQC'])); all_equipos.sort()\n",
    "all_pos = list(data_utils.get_col_universe_across_teams(teams, ['EQ_POS', 'EQC_POS'])); all_pos.sort()\n",
    "all_jrd = list(data_utils.get_col_universe_across_teams(teams, ['JRD'])); all_jrd.sort()\n",
    "all_ano = list(data_utils.get_col_universe_across_teams(teams, ['ANO'])); all_ano.sort()\n",
    "all_tipo = list(data_utils.get_col_universe_across_teams(teams, ['TIPO'])); all_tipo.sort()\n",
    "all_prev_res = list(data_utils.get_col_universe_across_teams(teams, ['PREV_RES'])); all_prev_res.sort()\n",
    "all_prev_g_eq = list(data_utils.get_col_universe_across_teams(teams, ['PREV_G_EQ'])); all_prev_g_eq.sort()\n",
    "all_prev_g_eqc = list(data_utils.get_col_universe_across_teams(teams, ['PREV_G_EQC'])); all_prev_g_eqc.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add missing categories to the categorical variables givn in cat_mapping in the form of (cat_var, universe)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapping = {\n",
    "    'EQ' : all_equipos,\n",
    "    'EQC' : all_equipos,\n",
    "#     'ES_LOC', currently not using this one since all teams have the universe already\n",
    "    'PREV_RES' : all_prev_res,\n",
    "    'PREV_G_EQ' : all_prev_g_eq,\n",
    "    'PREV_G_EQC' : all_prev_g_eqc,\n",
    "    'EQ_POS' : all_pos,\n",
    "    'EQC_POS': all_pos,\n",
    "    'JRD' : all_jrd,\n",
    "    'ANO' : all_ano, \n",
    "    'TIPO' : all_tipo,\n",
    "}\n",
    "data_utils.add_missing_categories_all_teams(teams, cat_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert teams to datasets by using fastai TabularList and then extracting the datasets from it**\n",
    "\n",
    "We do this since the team_ds's will get converted to tensor lists which we will use to build our dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_ds = data_utils.get_datasets_from_teams(teams, dep_vars, cat_vars, cont_vars, procs, './data/ligamx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teams_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the maximum (latest) jrd, ano, tipo across all teams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "JRD_POS = cat_vars.index('JRD')\n",
    "ANO_POS = cat_vars.index('ANO')\n",
    "TIPO_POS = cat_vars.index('TIPO')\n",
    "\n",
    "mx_jrd, mx_ano, mx_tipo = data_utils.get_max_jrd(teams_ds, JRD_POS, ANO_POS, TIPO_POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the jrds that must be included in the validation dataset and removed from the current training set for all teams(if present)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid_bptt = 5\n",
    "valid_jrds = data_utils.get_valid_jrds(n_valid_bptt, mx_jrd, mx_ano, mx_tipo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating validation dataset for all teams and removing validation jrds from training dataset if present()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_valid_ds = data_utils.split_valid_jrds(teams_ds, valid_jrds, n_valid_bptt, JRD_POS, ANO_POS, TIPO_POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(teams_valid_ds[0][1]) == n_valid_bptt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validating correctness of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Getting the last jrd, ano, tipo from the team at the 0th position in our teams_ds list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 16, 1, 540)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm = 0\n",
    "ps = len(teams_ds[tm][1])\n",
    "teams_ds[tm][0][0][ps-1][JRD_POS].item(), teams_ds[tm][0][0][ps-1][ANO_POS].item(), teams_ds[tm][0][0][ps-1][TIPO_POS].item(), ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Checking that all teams have a different categorical numbers**\n",
    "Note that this was fixed above by setting the universe of each categorical value across all teams to each individual team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_set = set()\n",
    "for i in range(len(teams_ds)):\n",
    "    assert(teams_ds[i][0][0][0][0].item() not in teams_set)\n",
    "    teams_set.add(teams_ds[i][0][0][0][0].item())\n",
    "teams_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## General Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4480097481722177 0.2806661251015435 0.27132412672623885\n"
     ]
    }
   ],
   "source": [
    "loc_wins, tie, vis_wins = len(df[df.RES == 2]), len(df[df.RES == 1]), len(df[df.RES==0])\n",
    "\n",
    "assert(loc_wins + tie + vis_wins == len(df))\n",
    "\n",
    "print(loc_wins/len(df), tie/len(df), vis_wins/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Custom dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rnn_tab_ds import RNNTabDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_training_bptt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "rnn_tab_ds = RNNTabDataset(teams_ds, n_training_bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "rnn_tab_ds_valid = RNNTabDataset(teams_valid_ds, n_valid_bptt, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_dl = DataLoader(rnn_tab_ds, batches, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr_dl_valid = DataLoader(rnn_tab_ds_valid, batches, shuffle=False, drop_last = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Optimal Learning Rate CLR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Class and function that help us a good learning rate for our model\n",
    "from opt_lr import CLR, find_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Once Cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Class that helps us implement one cylce in our model\n",
    "from one_cycle import OneCycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Setting up cuda if possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Getting model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# Class that contains the model to predict game results along a function that helps us identify matches in the games from a jornada\n",
    "from rnn_tabular_model import RnnTabularModel, MyTabularModel\n",
    "\n",
    "# Model utils\n",
    "from model_utils import get_matching_idxs, get_loss, pred, accuracy, get_res, view_predictions_and_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RnnTabularModel(nn.Module):\n",
    "    \"\"\"RnnTabularModel:\n",
    "    helps us apply an RNN to a tabular model\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_szs:ListSizes, n_cont:int, out_sz:int, out_sz_rnn:int, lyrs:int, bs:int, ps:float=0.,\n",
    "                 emb_drop:float=0., y_range:OptRange=None):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([embedding(ni, nf) for ni,nf in emb_szs]) #Correct\n",
    "        self.emb_drop = nn.Dropout(emb_drop) #Correct\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont) #Correct\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds) #Correct\n",
    "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range #Correct\n",
    "        \n",
    "        #rnn stuff\n",
    "        self.nh = n_cont + n_emb #Correct\n",
    "        self.rnn = nn.GRU(self.nh, self.nh, lyrs, batch_first=True, dropout=ps) #Check changing nh and adding relu activation(kaggle post)\n",
    "        self.h_o = nn.Linear(self.nh,out_sz_rnn) #Correct\n",
    "        self.bn = BatchNorm1dFlat(self.nh) #Correct\n",
    "        \n",
    "        self.lyrs = lyrs #Correct\n",
    "        self.bs = bs #Correct\n",
    "        self.reset_h()#Correct\n",
    "        \n",
    "        #rnn sub-result proccessing stuff\n",
    "        self.tab_mod = MyTabularModel([], out_sz_rnn*2, out_sz, [30, 15], [ps, ps], )\n",
    "\n",
    "    def forward(self, x_cat:Tensor, x_cont:Tensor) -> Tensor:\n",
    "        i_proc = torch.zeros(x_cat.shape[0], x_cat.shape[1], self.nh).to(device); #Correct\n",
    "        \n",
    "        for i_bptt in range(x_cat.shape[1]): #Correct\n",
    "            curr_cat = x_cat[:,i_bptt,:] #Correct\n",
    "            curr_cont = x_cont[:,i_bptt,:] #Correct\n",
    "            \n",
    "            if self.n_emb != 0: #Correct\n",
    "                x = [e(curr_cat[:,i]) for i,e in enumerate(self.embeds)] #Correct\n",
    "                x = torch.cat(x, 1) #Correct\n",
    "                x = self.emb_drop(x) #Correct\n",
    "            if self.n_cont != 0: #Correct\n",
    "                curr_cont = self.bn_cont(curr_cont) #Correct\n",
    "                x = torch.cat([x, curr_cont], 1) if self.n_emb != 0 else curr_cont #Correct\n",
    "            i_proc[:, i_bptt] = x #Checked that copying works by printing embeding changes. Maybe just check how copying like this works for pytorch, a way to do this is to check the weight of embedings to see if they are updating\n",
    "            \n",
    "        res, h = self.rnn(i_proc, self.h) #Correct\n",
    "        # if self.training: self.h = h.detach() #Correct       \n",
    "        self.h = h.detach() #Correct \n",
    "        \n",
    "        rnn_res = self.h_o(self.bn(res)) #Correct\n",
    "        \n",
    "        # new part, using results of both teams\n",
    "        rnn_res_list = []\n",
    "        # TODO: maybe change this code to python C?\n",
    "        for bptt_i in range(x_cat.shape[1]):\n",
    "            p_lst = get_matching_idxs(x_cat[:, bptt_i])\n",
    "            for eq, eq_c in p_lst:\n",
    "                rnn_res_list.append(torch.cat([rnn_res[eq][bptt_i], rnn_res[eq_c][bptt_i]]))\n",
    "\n",
    "        rnn_res_tens = torch.stack(rnn_res_list)\n",
    "        tab_res = self.tab_mod(tensor([]), rnn_res_tens)\n",
    "    \n",
    "        if self.y_range is not None: #Correct\n",
    "            tab_res = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(tab_res) + self.y_range[0] #Correct\n",
    "        \n",
    "        return tab_res #Correct\n",
    "    \n",
    "    def reset_h(self):\n",
    "        self.h = torch.zeros(self.lyrs, self.bs, self.nh).to(device) #Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Validation setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 5, 11])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_it = iter(curr_dl_valid)\n",
    "tst = next(curr_it)\n",
    "\n",
    "sample_cat = tst[0][0][0].type(torch.LongTensor).to(device)\n",
    "sample_cont = tst[0][1][0].to(device)\n",
    "sample_res_not_proc = tst[1][0].type(torch.LongTensor).to(device)\n",
    "sample_res = get_res(sample_cat, sample_res_not_proc)\n",
    "\n",
    "sample_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup and model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EQ', 'EQC', 'ES_LOC', 'EQ_POS', 'EQC_POS', 'JRD', 'ANO', 'TIPO', 'PREV_RES', 'PREV_G_EQ', 'PREV_G_EQC']\n"
     ]
    }
   ],
   "source": [
    "print(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ges(n_cat):\n",
    "    return min(600, round(1.6 * n_cat**0.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emb_sz(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           EQ        EQC       ES_LOC   EQ_POS    EQC_POS  JRD       ANO      TIPO    P_RES   P_G_EQ   P_G_EQC\n",
    "emb_szs = [(29, 11), (29, 11), (3, 5), (21, 10), (21, 10), (20, 0), (17, 0), (3, 0), (4, 10), (11, 5), (11, 5)]\n",
    "n_cont = len(cont_vars)\n",
    "out_sz = 3\n",
    "out_sz_rnn = 20\n",
    "lyrs = 2\n",
    "bs = 28\n",
    "dropout_embeds = 0.3\n",
    "dropout_reg = 0.3\n",
    "\n",
    "wd = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating model instance, loss criterion and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # Instantiate the model with hyperparameters\n",
    "    global model\n",
    "    global n_epochs\n",
    "    global lr\n",
    "    global lr_end\n",
    "    global criterion\n",
    "    global optimizer\n",
    "    model = RnnTabularModel(emb_szs, n_cont, out_sz, out_sz_rnn, lyrs, bs, dropout_reg, dropout_embeds)\n",
    "\n",
    "    # We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define hyperparameters\n",
    "    n_epochs = 25\n",
    "    lr = 1e-2\n",
    "    lr_end = 1e-3\n",
    "\n",
    "    # Define Loss, Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = wd)\n",
    "create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def find_lr(loss_func, opt, clr, model):\n",
    "# clr = CLR(curr_dl)\n",
    "# find_lr(criterion, optimizer, clr, model, curr_dl)\n",
    "# clr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizer_utils import changeLr, changeLrAndMomentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_lr(lr_s, lr_e, epoch, ttl_epochs):\n",
    "    K = 20.\n",
    "    x = epoch/(ttl_epochs-1)\n",
    "    scalar = 1/(1. + math.exp(K * x - K/2.5))\n",
    "    return lr_e + (lr_s - lr_e) * scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(n_epochs)], [get_lr(lr, lr_end, i , n_epochs) for i in range(n_epochs)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training loop:**\n",
    "\n",
    "Parece que:\n",
    "    - Mayor embedding size es mejor\n",
    "    - Mejor performance con ultimos 3 embeddings y ponerle 0 a los embeddings de JRD, ANO, TIPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25....... Train Loss: 1.1258...... Last batch train Loss: 1.0880...... Valid Loss: 1.0742...... Valid acc: 0.4667 LR: 0.0100\n",
      "Epoch: 2/25....... Train Loss: 1.0941...... Last batch train Loss: 1.0787...... Valid Loss: 1.0642...... Valid acc: 0.4667 LR: 0.0100\n",
      "Epoch: 3/25....... Train Loss: 1.0915...... Last batch train Loss: 1.0722...... Valid Loss: 1.0515...... Valid acc: 0.5556 LR: 0.0100\n",
      "Epoch: 4/25....... Train Loss: 1.0723...... Last batch train Loss: 1.0458...... Valid Loss: 1.0258...... Valid acc: 0.5333 LR: 0.0100\n",
      "Epoch: 5/25....... Train Loss: 1.0581...... Last batch train Loss: 1.0270...... Valid Loss: 0.9788...... Valid acc: 0.5556 LR: 0.0099\n",
      "Epoch: 6/25....... Train Loss: 1.0585...... Last batch train Loss: 1.0256...... Valid Loss: 0.9798...... Valid acc: 0.5778 LR: 0.0098\n",
      "Epoch: 7/25....... Train Loss: 1.0534...... Last batch train Loss: 1.0131...... Valid Loss: 0.9686...... Valid acc: 0.5778 LR: 0.0096\n",
      "Epoch: 8/25....... Train Loss: 1.0467...... Last batch train Loss: 1.0004...... Valid Loss: 1.0129...... Valid acc: 0.5556 LR: 0.0091\n",
      "Epoch: 9/25....... Train Loss: 1.0413...... Last batch train Loss: 1.0067...... Valid Loss: 0.9678...... Valid acc: 0.6000 LR: 0.0081\n",
      "Epoch: 10/25....... Train Loss: 1.0313...... Last batch train Loss: 0.9640...... Valid Loss: 0.9863...... Valid acc: 0.5333 LR: 0.0066\n",
      "Epoch: 11/25....... Train Loss: 1.0191...... Last batch train Loss: 0.9848...... Valid Loss: 0.9960...... Valid acc: 0.5556 LR: 0.0048\n",
      "Epoch: 12/25....... Train Loss: 1.0038...... Last batch train Loss: 0.9661...... Valid Loss: 0.9986...... Valid acc: 0.5556 LR: 0.0031\n",
      "Epoch: 13/25....... Train Loss: 0.9859...... Last batch train Loss: 0.9363...... Valid Loss: 1.0407...... Valid acc: 0.5333 LR: 0.0021\n",
      "Epoch: 14/25....... Train Loss: 0.9700...... Last batch train Loss: 0.8935...... Valid Loss: 1.0289...... Valid acc: 0.5556 LR: 0.0015\n",
      "Epoch: 15/25....... Train Loss: 0.9467...... Last batch train Loss: 0.9184...... Valid Loss: 0.9954...... Valid acc: 0.5556 LR: 0.0012\n",
      "Epoch: 16/25....... Train Loss: 0.9435...... Last batch train Loss: 0.8578...... Valid Loss: 1.0323...... Valid acc: 0.5333 LR: 0.0011\n",
      "Epoch: 17/25....... Train Loss: 0.9338...... Last batch train Loss: 0.8341...... Valid Loss: 1.0480...... Valid acc: 0.5111 LR: 0.0010\n",
      "Epoch: 18/25....... Train Loss: 0.9250...... Last batch train Loss: 0.8911...... Valid Loss: 1.0313...... Valid acc: 0.4667 LR: 0.0010\n",
      "Epoch: 19/25....... Train Loss: 0.9104...... Last batch train Loss: 0.8354...... Valid Loss: 1.0412...... Valid acc: 0.4444 LR: 0.0010\n",
      "Epoch: 20/25....... Train Loss: 0.9054...... Last batch train Loss: 0.8410...... Valid Loss: 1.0755...... Valid acc: 0.4889 LR: 0.0010\n",
      "Epoch: 21/25....... Train Loss: 0.8887...... Last batch train Loss: 0.8778...... Valid Loss: 1.0731...... Valid acc: 0.5111 LR: 0.0010\n",
      "Epoch: 22/25....... Train Loss: 0.8894...... Last batch train Loss: 0.8395...... Valid Loss: 1.0487...... Valid acc: 0.5333 LR: 0.0010\n",
      "Epoch: 23/25....... Train Loss: 0.8742...... Last batch train Loss: 0.8421...... Valid Loss: 1.0572...... Valid acc: 0.4444 LR: 0.0010\n",
      "Epoch: 24/25....... Train Loss: 0.8615...... Last batch train Loss: 0.8251...... Valid Loss: 1.1056...... Valid acc: 0.4889 LR: 0.0010\n",
      "Epoch: 25/25....... Train Loss: 0.8500...... Last batch train Loss: 0.7993...... Valid Loss: 1.1797...... Valid acc: 0.4667 LR: 0.0010\n",
      "Done, final validation loss: 1.1797257661819458, validation_accuracy: 0.4666666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.1797, grad_fn=<NllLossBackward>), 0.4666666666666667)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_model(should_print = True):\n",
    "    # Training Run\n",
    "    # Average loss in all batches\n",
    "    train_loss_avgs = [0 for i in range(len(iter(curr_dl)))]\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        dl_it = iter(curr_dl)\n",
    "        changeLr(get_lr(lr, lr_end, epoch-1, n_epochs), optimizer)\n",
    "        \n",
    "        # resetting our h mtrx and setting model to train mode\n",
    "        model.reset_h()\n",
    "        model.train()\n",
    "\n",
    "        # loss accumulative across batches\n",
    "        ttl_train_loss = 0;\n",
    "        for i_batch, curr_batch in enumerate(dl_it):\n",
    "\n",
    "            optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "            x_cat, x_cont = curr_batch[0][0][0].type(torch.LongTensor).to(device), curr_batch[0][1][0].to(device)\n",
    "\n",
    "            # getting cat'ed res from current batch \n",
    "            res = get_res(x_cat, curr_batch[1][0].type(torch.LongTensor).to(device))\n",
    "\n",
    "            # calculating model output\n",
    "            output = model(x_cat, x_cont)\n",
    "            loss = criterion(output, res)\n",
    "            loss.backward() # Does backpropagation and calculates gradients\n",
    "            optimizer.step() # Updates the weights accordingly\n",
    "\n",
    "            # updating ttl train loss\n",
    "            ttl_train_loss += loss.item()\n",
    "\n",
    "            # updating loss averages\n",
    "            train_loss_avgs[i_batch] += loss.item()/(n_epochs)\n",
    "\n",
    "            if i_batch == len(dl_it)-1:\n",
    "                model.eval()\n",
    "                loss_valid = get_loss(model, sample_cat, sample_cont, sample_res)\n",
    "                accuracy_valid = accuracy(model, sample_cat, sample_cont, sample_res)\n",
    "\n",
    "        if epoch%1 == 0 and should_print:\n",
    "            print(\"Epoch: {}/{}.......\".format(epoch, n_epochs), end=' ')\n",
    "            print(\"Train Loss: {:.4f}......\".format(ttl_train_loss/(len(dl_it))), end = ' ')\n",
    "            print(\"Last batch train Loss: {:.4f}......\".format(loss.item()), end = ' ')\n",
    "            print(\"Valid Loss: {:.4f}......\".format(loss_valid.item()), end = ' ')\n",
    "            print(\"Valid acc: {:.4f}\".format(accuracy_valid), end=' ')\n",
    "            print(\"LR: {:.4f}\".format(optimizer.param_groups[0]['lr']))\n",
    "    print(f'Done, final validation loss: {loss_valid}, validation_accuracy: {accuracy_valid}')\n",
    "    return loss_valid, accuracy_valid\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, final validation loss: 1.0241369009017944, validation_accuracy: 0.5333333333333333\n",
      "Done, final validation loss: 0.9457118511199951, validation_accuracy: 0.5333333333333333\n",
      "Done, final validation loss: 1.0068105459213257, validation_accuracy: 0.5333333333333333\n",
      "Done, final validation loss: 0.9958558082580566, validation_accuracy: 0.5555555555555556\n",
      "Done, final validation loss: 0.971358060836792, validation_accuracy: 0.4666666666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-7488e5619a3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{valids.mean()}, {valids.std()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{accs.mean()}, {accs.std()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrun_several\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-7488e5619a3a>\u001b[0m in \u001b[0;36mrun_several\u001b[0;34m(runs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mvalids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-c9f10ea9cf94>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(should_print)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Does backpropagation and calculates gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Updates the weights accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# updating ttl train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl_mp/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_several(runs = 7):\n",
    "    valids = []\n",
    "    accs = []\n",
    "    for run in range(runs):\n",
    "        create_model()\n",
    "        val, acc = run_model(Treu)\n",
    "        valids.append(val)\n",
    "        accs.append(acc)\n",
    "    valids = tensor(valids)\n",
    "    accs = tensor(accs)\n",
    "    print(valids)\n",
    "    print(accs)\n",
    "    print(f'{valids.mean()}, {valids.std()}')\n",
    "    print(f'{accs.mean()}, {accs.std()}')\n",
    "run_several()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6d196c806e88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mabc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "abc = tensor([])\n",
    "\n",
    "torch.cat((abc, tensor(2).view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"./models/1/1\"\n",
    "# torch.save(model.state_dict(), save_path)\n",
    "# model = RnnTabularModel(emb_szs, n_cont, out_sz, lyrs, bs, dropout_reg, dropout_embeds)\n",
    "# model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    plt.xlabel(\"batch\")\n",
    "    plt.ylabel(\"Losses\")\n",
    "    plt.plot([i+1 for i in range(len(losses))], losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(loss_avgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_pred, sample_prob, m_out= pred(model, sample_cat, sample_cont, sample_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy(model, sample_cat, sample_cont, sample_res)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
